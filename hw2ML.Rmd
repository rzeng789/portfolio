#Q1
library(tidyverse)
library(tidymodels)
#read data
abalone <- read_csv("/Users/ruilanzeng/Downloads/abalone.data",
                    col_names = c("sex", "length", "diameter", "height",
                                  "whole_weight", "shucked_weight",
                                  "viscera_weight", "shell_weight", "rings"))
abalone <- abalone %>%
  mutate(age = rings + 1.5)
summary(abalone$age)
abalone %>%
  ggplot(aes(x = age)) +
  geom_histogram(bins = 30, color = "white") +
  labs(title = "Distribution of Abalone Age",
       x = "Age (years)",
       y = "Count")

#Range: Ages span roughly from about 2.5 years (1 ring + 1.5) up to around 30.5 years (29 rings + 1.5).
#Center: The mean age tends to be around 9–10 years, with the median slightly lower (often ~9 years).
#Spread: The interquartile range (IQR) is usually in the 6–13 years band, indicating most abalones are in that middle age bracket.
#Shape: The histogram is unimodal with a right (positive) skew—there are many younger specimens and a tapering tail of older individuals.
#Outliers: A few very old abalones (ages above ~20) appear as isolated bars on the far right.

#Q2
#Install rlang
install.packages("rlang")
library(tidymodels)      # loads rsample namespace
library(rsample)         # now initial_split() is available

set.seed(123)
abalone_split  <- rsample::initial_split(abalone, prop = 0.75, strata = rings)

#extract the training and testing sets
abalone_train  <- rsample::training(abalone_split)
abalone_test   <- rsample::testing(abalone_split)
#Q3
library(tidymodels)

abalone_rec <- recipe(age ~ ., data = abalone_train) %>%
  

  step_rm(rings) %>%
  step_dummy(sex, one_hot = TRUE) %>%

  step_interact(terms = ~ matches("^sex_"):shucked_weight) %>%
  step_interact(terms = ~ length:diameter) %>%
  step_interact(terms = ~ shucked_weight:shell_weight) %>%
  
  #Center and scale everything
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  prep()

#inspect the processed training data:
juice(abalone_rec)
#We want to drop rings because it’s literally how we compute age (age = rings + 1.5), so feeding it back into the model is akin to giving the “answer key” as an input. That creates data leakage—your model will learn that exact relationship and appear to predict perfectly, but it tells you nothing about how the other shell measurements (length, weight, etc.) actually relate to an abalone’s age. By excluding rings, you force the model to discover the signal in the biological features you care about, and you get a realistic measure of how well you can predict age without cracking open the shell.
#Q4
library(tidymodels)  # loads recipes, parsnip, workflows, etc.
abalone_rec <- recipe(age ~ ., data = abalone_train) %>%
  step_rm(rings) %>%
  step_dummy(sex) %>%
  step_interact( terms = ~ matches("^sex_"):shucked_weight ) %>%
  step_interact( terms = ~ length:diameter ) %>%
  step_interact( terms = ~ shucked_weight:shell_weight ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())
# 2. Model spec
lm_spec <- linear_reg(mode = "regression") %>%
  set_engine("lm")
# 3. Build workflow
lm_wf <- 
  workflow() %>%
  add_recipe(abalone_rec) %>%
  add_model(lm_spec)
lm_fit <- fit(lm_wf, data = abalone_train)
# 4. Fit it (this will prep the recipe under the hood)
lm_fit <- fit(lm_wf, data = abalone_train)

lm_fit
#Q5
install.packages("kknn")
library(parsnip)

knn_spec <- 
  nearest_neighbor(mode = "regression", neighbors = 7) %>% 
  set_engine("kknn")
library(workflows)

knn_wf <- 
  workflow() %>% 
  add_recipe(abalone_rec) %>% 
  add_model(knn_spec)

knn_fit <- fit(knn_wf, data = abalone_train)

#Q6
library(tidymodels)   # loads parsnip, recipes, workflows, etc.
lm_wf <- 
  workflow() %>% 
  add_model(lm_spec) %>% 
  add_recipe(abalone_rec)

lm_fit <- 
  lm_wf %>% 
  fit(data = abalone_train)

# 2. KNN Workflow
knn_wf <- 
  workflow() %>% 
  add_model(knn_spec) %>% 
  add_recipe(abalone_rec)

knn_fit <- 
  knn_wf %>% 
  fit(data = abalone_train)

# Inspect fitted objects
lm_fit
knn_fit

#Q7
library(tibble)
new_abalone <- tibble(
  sex            = "F",       # female
  length         = 0.50,
  diameter       = 0.10,
  height         = 0.30,
  whole_weight   = 4,
  shucked_weight = 1,
  viscera_weight = 2,
  shell_weight   = 1,
  rings          = NA_real_   # dummy so the recipe blueprint can forge new data
)

predicted <- predict(lm_fit, new_data = new_abalone)
predicted

#Q8
library(yardstick)
library(broom)       # for augment()

#Define your metric set
metrics <- metric_set(rsq, rmse, mae)

#Augment test data with predictions
lm_aug <- lm_fit %>%
  augment(new_data = abalone_test)

#Compute metrics for the linear model
lm_metrics <- lm_aug %>%
  metrics(truth = age, estimate = .pred)

knn_aug <- knn_fit %>%
  augment(new_data = abalone_test)

knn_metrics <- knn_aug %>%
  metrics(truth = age, estimate = .pred)

#Inspect results
lm_metrics
knn_metrics

#Q9
#When I line up the numbers, it’s clear the linear regression came out on top. Its R² of about 0.54 means it explains just over half of the variation in abalone age on the test set, whereas KNN only captures around 0.48 of that variation. The linear model’s RMSE (2.21) and MAE (1.55) are also a bit lower than KNN’s (2.35 and 1.62), so on average its age predictions fall closer to the true values. I think this happened because the relationship between shell measurements and age really is mostly linear, especially once we added those interaction terms. Giving the model a global equation to fit means it can pull together all the patterns we engineered. KNN, by contrast, tries to lean on its seven “nearest neighbors” in a fairly high-dimensional space, and in practice those neighbors aren’t always that similar—so its guesses end up noisier.
#Honestly, I’m not too surprised. In a problem like this—with a few thousand examples and a handful of well-chosen predictors—a clean, parametric approach often beats a vanilla neighbor algorithm. It does make me appreciate, though, how important feature engineering and domain knowledge are: those interaction terms really boosted the linear model’s power. If I wanted KNN to catch up, I’d try tuning k, weighting distances, or even doing a bit of dimensionality reduction—but for now, the linear model clearly has the edge.

